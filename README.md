# SK_Rookies_Mini_Project1

# 잡파인드 (JobFind) 프로젝트

## 프로젝트 개요
'잡파인드'는 인크루트나 잡코리아와 같은 취업 사이트를 클론 코딩하는 미니 프로젝트입니다. 학습한 기술 스택을 활용하여 데이터 수집부터 웹 애플리케이션 구현까지 전체 데이터 파이프라인을 구축합니다.

## 프로젝트 기간
- **시작일**: 2025년 4월 16일
- **종료일**: 2025년 4월 22일 (총 5일)

## 기술 스택
- **웹 스크래핑**: Selenium
- **데이터 분석**: pandas
- **데이터 시각화**: matplotlib, seaborn
- **데이터베이스**: pymysql, sqlalchemy
- **웹 애플리케이션**: streamlit

## 프로젝트 목표
1. 배운 파이썬 기술을 통합적으로 활용하여 하나의 완성된 데이터 프로젝트 구현
2. 데이터 수집 → 저장 → 분석 → 시각화 → 웹앱 구현 과정을 실습
3. 개인의 이해도, 기술 습득 정도, 문제 해결 능력을 종합적으로 보여주는 결과물 제작

## 작업 환경
- **GitHub**
- **Notion**
- **Working Driver(Naver works)**

## 주요 기능
- 취업 정보 데이터 수집 및 저장
- 지역별, 산업별, 경력별 취업 정보 분석
- 급여 정보, 필수 스킬 등 주요 정보 시각화
- 검색 및 필터링 기능을 갖춘 웹 인터페이스

## 역할 분담
- 데이터 수집 담당: 지재현
- 데이터베이스 설계 및 구축: 지재현
- 데이터 분석 및 시각화: 조은지
- 웹 애플리케이션 개발: 황지영

## 개발 일정
- 1일차: 프로젝트 기획 및 환경 설정, 웹 스크래핑 설계
- 2일차: 데이터 수집 및 데이터베이스 구축
- 3일차: 데이터 전처리 및 분석
- 4일차: 시각화 및 웹 애플리케이션 개발
- 5일차: 전체 시스템 통합 및 디버깅, 프로젝트 마무리

## 설치 및 실행 방법
```bash
# 저장소 클론
git clone [GitHub 주소]

# 필요 패키지 설치
pip install -r requirements.txt

# 애플리케이션 실행
streamlit run app.py
```

## 프로젝트 구조
```
root/
├── data/               # 수집한 데이터 파일
├── database/           # 데이터베이스 관련 코드
├── scraper/            # 웹 스크래핑 모듈
├── analysis/           # 데이터 분석 코드
├── visualization/      # 데이터 시각화 코드
├── app/                # Streamlit 웹 애플리케이션
├── requirements.txt    # 필요 패키지 목록
└── README.md           # 프로젝트 설명
```

## 팀원
- [조은지](https://github.com/lemongza)
- [지재현](https://github.com/J-millar99/)
- [황지영](GitHub 프로필 링크)
