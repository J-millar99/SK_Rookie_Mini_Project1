{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c75ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import json, time, asyncio, aiohttp\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "115883fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "req_header = { \"user-agent\" : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798919fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch(session, url, headers=None):\n",
    "    try:\n",
    "        async with session.get(url, headers=headers) as response:\n",
    "            if response.status == 200:\n",
    "                content = await response.read()\n",
    "                try:\n",
    "                    return content.decode('euc-kr')\n",
    "                except UnicodeDecodeError:\n",
    "                    try:\n",
    "                        return content.decode('utf-8')\n",
    "                    except UnicodeDecodeError:\n",
    "                        return content.decode('cp949', errors='replace')\n",
    "            else:\n",
    "                print(f\"에러 코드 = {response.status}, URL: {url}\")\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        print(f\"요청 오류: {e}, URL: {url}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1cf2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_page_async(id2, page_url, occ1_id_dict, occ2_id_dict, session):\n",
    "    result = []\n",
    "    \n",
    "    try:\n",
    "        occ1_id, occ2_name = occ2_id_dict.get(id2, (None, \"알 수 없는 직업\"))\n",
    "        if occ1_id is None:\n",
    "            return []\n",
    "            \n",
    "        occ1_name = occ1_id_dict.get(occ1_id, \"알 수 없는 대분류\")\n",
    "        \n",
    "        html = await fetch(session, page_url, req_header)\n",
    "        if html:\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            li_tag_list = soup.select(\"li.c_col\")\n",
    "            \n",
    "            job_tasks = []\n",
    "            for li_tag in li_tag_list:\n",
    "                first_cell = li_tag.find('div', class_='cell_first')\n",
    "                company_name = first_cell.find('a').text if first_cell and first_cell.find('a') else \"\"\n",
    "                \n",
    "                mid_cell = li_tag.find('div', class_='cell_mid')\n",
    "                title_tag = mid_cell.find('a') if mid_cell else None\n",
    "                \n",
    "                if title_tag and title_tag.get(\"href\"):\n",
    "                    title = title_tag.text\n",
    "                    title_url = title_tag[\"href\"]\n",
    "                    \n",
    "                    job_tasks.append(get_employ_info_async(id2, title_url, session))\n",
    "            \n",
    "            employ_info_list = await asyncio.gather(*job_tasks)\n",
    "            \n",
    "            # 결과 조합\n",
    "            for i, li_tag in enumerate(li_tag_list):\n",
    "                if i < len(employ_info_list):\n",
    "                    first_cell = li_tag.find('div', class_='cell_first')\n",
    "                    company_name = first_cell.find('a').text if first_cell and first_cell.find('a') else \"\"\n",
    "                    \n",
    "                    mid_cell = li_tag.find('div', class_='cell_mid')\n",
    "                    title_tag = mid_cell.find('a') if mid_cell else None\n",
    "                    \n",
    "                    if title_tag and title_tag.get(\"href\"):\n",
    "                        title = title_tag.text\n",
    "                        title_url = title_tag[\"href\"]\n",
    "                        \n",
    "                        job_info = {\n",
    "                            \"회사명\": company_name,\n",
    "                            \"채용공고\": title,\n",
    "                            \"URL\": title_url,\n",
    "                            \"대분류\": occ1_name,\n",
    "                            \"소분류\": occ2_name,\n",
    "                            **employ_info_list[i]\n",
    "                        }\n",
    "                        \n",
    "                        result.append(job_info)\n",
    "    except Exception as e:\n",
    "        print(f\"페이지 처리 오류: {e}, occ2_id: {id2}, URL: {page_url}\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39491a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_occ1_id(soup):\n",
    "    occ1_id_dict = {}\n",
    "    for button in soup.select(\"ul#occ1_div li button[data-item-val]\"):\n",
    "        occ1_id = button.get(\"data-item-val\")\n",
    "        occ1_name = button.find_next(\"span\").text if button.find_next(\"span\") else \"\"\n",
    "        if occ1_id and occ1_name:\n",
    "            occ1_id_dict[occ1_id] = occ1_name\n",
    "    return occ1_id_dict\n",
    "\n",
    "\n",
    "def select_occ2_id(soup, id_list):\n",
    "    occ2_id_dict = {}\n",
    "    all_occ2_buttons = soup.select(\"ul[id^='occ2_ul_'] li button[data-item-val]\")\n",
    "    \n",
    "    for button in all_occ2_buttons:\n",
    "        data_val = button.get(\"data-item-val\")\n",
    "        if data_val and \"_\" in data_val:\n",
    "            occ1_id, occ2_id = data_val.split(\"_\")\n",
    "            if occ1_id in id_list:\n",
    "                occ2_name = button.find_next(\"span\").text if button.find_next(\"span\") else \"\"\n",
    "                occ2_id_dict[occ2_id] = (occ1_id, occ2_name)\n",
    "    \n",
    "    return occ2_id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b956478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def calculate_page_count(count_str):\n",
    "    count = int(count_str.replace(\",\", \"\"))\n",
    "    page = ((count - 1) // 30) + 1\n",
    "    return page\n",
    "\n",
    "async def get_page_url_list_async(occ2_id_dict):\n",
    "    count_url = \"https://job.incruit.com/s_common/searchjob/v3/searchjob_getcount_ajax.asp?occ2=\"\n",
    "    base_url = \"https://job.incruit.com/jobdb_list/searchjob.asp?articlecount=30&occ2=\"\n",
    "    \n",
    "    page_url_list = []\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for occ2_id in occ2_id_dict.keys():\n",
    "            tasks.append(fetch(session, count_url + occ2_id, req_header))\n",
    "        \n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        \n",
    "        for i, (occ2_id, response) in enumerate(zip(occ2_id_dict.keys(), responses)):\n",
    "            if response:\n",
    "                page_num = calculate_page_count(response)\n",
    "                new_urls = [(occ2_id, f\"{base_url}{occ2_id}&page={page_index}\") \n",
    "                           for page_index in range(1, page_num + 1)]\n",
    "                page_url_list.extend(new_urls)\n",
    "    \n",
    "    return page_url_list\n",
    "\n",
    "def first_cell_parser(li_tag):\n",
    "    first_cell = li_tag.find('div', class_='cell_first') # 기업 이름과 태그\n",
    "    company = first_cell.find('a')\n",
    "    return company.text\n",
    "\n",
    "def mid_cell_parser(li_tag):\n",
    "    mid_cell = li_tag.find('div', class_='cell_mid') # 채용 공고\n",
    "    title = mid_cell.find('a')\n",
    "    href = title[\"href\"]\n",
    "    return title.text, href\n",
    "\n",
    "async def get_employ_info_async(id, link, session):\n",
    "    employ_info = {}\n",
    "    try:\n",
    "        html = await fetch(session, link, req_header)\n",
    "        if html:\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            info_items = soup.select('ul.jc_list li div.txt em')\n",
    "            \n",
    "            keys = ['고용형태', '경력', '근무지역', '학력', '급여조건']\n",
    "            employ_info = {keys[i]: info_items[i].text for i in range(min(len(keys), len(info_items)))}\n",
    "    except Exception as e:\n",
    "        print(f\"정보 추출 중 오류: {e}, URL: {link}\")\n",
    "    \n",
    "    return employ_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972cd98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def classify_jobs_async(page_url_list, occ1_id_dict, occ2_id_dict, batch_size=10):\n",
    "    all_results = []\n",
    "    \n",
    "    # 배치 처리로 동시 요청 수 제한\n",
    "    for i in range(0, len(page_url_list), batch_size):\n",
    "        batch = page_url_list[i:i+batch_size]\n",
    "        \n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            tasks = [process_page_async(id2, page_url, occ1_id_dict, occ2_id_dict, session) \n",
    "                    for id2, page_url in batch]\n",
    "            \n",
    "            batch_results = await asyncio.gather(*tasks)\n",
    "            \n",
    "            for results in batch_results:\n",
    "                all_results.extend(results)\n",
    "        \n",
    "        print(f\"배치 {i//batch_size + 1}/{(len(page_url_list) + batch_size - 1)//batch_size} 완료. 현재까지 {len(all_results)}개 항목 수집\")\n",
    "        \n",
    "        await asyncio.sleep(1)\n",
    "    \n",
    "    job_data = {}\n",
    "    for job in all_results:\n",
    "        occ1_name = job.pop(\"대분류\", \"알 수 없는 대분류\")\n",
    "        occ2_name = job.pop(\"소분류\", \"알 수 없는 직업\")\n",
    "        \n",
    "        if occ1_name not in job_data:\n",
    "            job_data[occ1_name] = {}\n",
    "        \n",
    "        if occ2_name not in job_data[occ1_name]:\n",
    "            job_data[occ1_name][occ2_name] = []\n",
    "        \n",
    "        job_data[occ1_name][occ2_name].append(job)\n",
    "    \n",
    "    return job_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b520e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(data, filename=\"incruit_jobs.json\"):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"{filename}에 데이터가 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d6cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_main():\n",
    "    url = \"https://job.incruit.com/jobdb_list/searchjob.asp?occ1=100&occ1=101&occ1=102&occ1=150&occ1=104&occ1=160&occ1=110&occ1=106&occ1=140&occ1=120&occ1=170&occ1=103&occ1=107&occ1=190&occ1=200&occ1=210&occ1=130\"\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        html = await fetch(session, url, req_header)\n",
    "        \n",
    "        if html:\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            \n",
    "            occ1_id_dict = select_occ1_id(soup)\n",
    "            print(f\"대분류(occ1) 개수: {len(occ1_id_dict)}\")\n",
    "            \n",
    "            occ2_id_dict = select_occ2_id(soup, occ1_id_dict.keys())\n",
    "            print(f\"소분류(occ2) 개수: {len(occ2_id_dict)}\")\n",
    "            \n",
    "            page_url_list = await get_page_url_list_async(occ2_id_dict)\n",
    "            print(f\"총 페이지 수: {len(page_url_list)}\")\n",
    "            \n",
    "            print(\"전체 데이터 수집을 시작합니다...\")\n",
    "            job_data = await classify_jobs_async(page_url_list, occ1_id_dict, occ2_id_dict, batch_size=20)\n",
    "            \n",
    "            save_to_json(job_data)\n",
    "        else:\n",
    "            print(\"초기 페이지 접근 오류\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42362d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주피터 노트북에서 비동기 코드 실행을 위한 방법\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()  # 이벤트 루프 중첩 허용\n",
    "\n",
    "# 이제 asyncio.run() 사용 가능\n",
    "asyncio.run(async_main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
